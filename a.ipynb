{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "# Encoder\n",
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, channel_ratio=1, kernel_size=3, padding=1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.conv1 = self.conv_block(in_channels, out_channels, channel_ratio, kernel_size, padding)\n",
    "        self.conv2 = self.conv_block(out_channels, out_channels, channel_ratio, kernel_size, padding)\n",
    "        self.residual_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels)\n",
    "        )\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels, channel_ratio, kernel_size, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=in_channels*channel_ratio, kernel_size=kernel_size, stride=1, padding=padding, groups=in_channels),\n",
    "            nn.BatchNorm2d(num_features=in_channels*channel_ratio),\n",
    "            nn.Conv2d(in_channels=in_channels*channel_ratio, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual_conv(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x +  residual \n",
    "        return x                \n",
    "     \n",
    "     \n",
    "# Decoder \n",
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, channel_ratio=1, kernel_size=3, padding=1):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels*channel_ratio, kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(num_features=out_channels*channel_ratio),\n",
    "            nn.Conv2d(in_channels=out_channels*channel_ratio, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=in_channels*channel_ratio, kernel_size=kernel_size, stride=1, padding=padding, groups=in_channels),\n",
    "            nn.BatchNorm2d(num_features=in_channels*channel_ratio),\n",
    "            nn.Conv2d(in_channels=in_channels*channel_ratio, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.residual_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, attention):\n",
    "        residual = self.residual_conv(x)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.cat((attention, x), dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = x + residual \n",
    "        return x\n",
    "       \n",
    "          \n",
    "# Bottleneck\n",
    "class BottleNeckBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, channel_ratio=1, kernel_size=3, padding=1):\n",
    "        super(BottleNeckBlock, self).__init__()\n",
    "        self.conv1 = self.conv_block(in_channels, in_channels, channel_ratio, kernel_size, padding)\n",
    "        self.conv2 = self.conv_block(in_channels, out_channels, channel_ratio, kernel_size, padding)\n",
    "        self.residual_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "        )\n",
    "    \n",
    "    def conv_block(self, in_channels, out_channels, channel_ratio, kernel_size, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=in_channels*channel_ratio, kernel_size=kernel_size, stride=1, padding=padding, groups=in_channels),\n",
    "            nn.BatchNorm2d(num_features=in_channels*channel_ratio),\n",
    "            nn.Conv2d(in_channels=in_channels*channel_ratio, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.residual_conv(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x + residual \n",
    "        return x\n",
    "\n",
    "\n",
    "# Attention\n",
    "class AttentionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, g_channels):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=g_channels, out_channels=g_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=g_channels)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=g_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=g_channels)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=g_channels, out_channels=1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=1)\n",
    "        )\n",
    "        self.upsampler = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.final_conv = nn.Conv2d(in_channels=in_channels, out_channels=g_channels, kernel_size=1, stride=1, padding=0)\n",
    "            \n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        x1 = self.upsampler(x1)\n",
    "        out = self.relu(g1+x1)\n",
    "        out = self.psi(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.upsampler(x) * out \n",
    "        out = self.final_conv(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# Final UNet\n",
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=4, out_channels=3):\n",
    "        \n",
    "        super(UNet, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.encoder1 = EncoderBlock(in_channels=in_channels, out_channels=64)\n",
    "        self.encoder2 = EncoderBlock(in_channels=64, out_channels=128)\n",
    "        self.encoder3 = EncoderBlock(in_channels=128, out_channels=256)\n",
    "        self.encoder4 = EncoderBlock(in_channels=256, out_channels=512)\n",
    "        \n",
    "        self.bottleneck = BottleNeckBlock(in_channels=512, out_channels=1024)\n",
    "\n",
    "        self.att1 = AttentionBlock(in_channels=1024, g_channels=512)\n",
    "        self.att2 = AttentionBlock(in_channels=512, g_channels=256)\n",
    "        self.att3 = AttentionBlock(in_channels=256, g_channels=128)\n",
    "        self.att4 = AttentionBlock(in_channels=128, g_channels=64)\n",
    "        \n",
    "        self.decoder1 = DecoderBlock(in_channels=1024, out_channels=512)\n",
    "        self.decoder2 = DecoderBlock(in_channels=512, out_channels=256)\n",
    "        self.decoder3 = DecoderBlock(in_channels=256, out_channels=128)\n",
    "        self.decoder4 = DecoderBlock(in_channels=128, out_channels=64)\n",
    "        \n",
    "        self.output_conv = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "        \n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        d1 = self.decoder1(b, self.att1(b, e4))\n",
    "        d2 = self.decoder2(d1, self.att2(d1, e3))\n",
    "        d3 = self.decoder3(d2, self.att3(d2, e2))\n",
    "        d4 = self.decoder4(d3, self.att4(d3, e1))\n",
    "        \n",
    "        out = self.output_conv(d4)\n",
    "            \n",
    "        return out\n",
    "0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
