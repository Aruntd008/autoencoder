{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"C:/Users/Arun/pytorch/datasxts/celebA\",  transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (3): DownsampleBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (6): DownsampleBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (9): DownsampleBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    )\n",
      "    (10): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (11): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (12): DownsampleBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    )\n",
      "    (13): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (14): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (15): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (16): NonLocalBlock(\n",
      "      (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (theta): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (phi): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (g): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (output_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (17): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (18): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "    (19): SiLU()\n",
      "    (20): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Output shape: torch.Size([4, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "from encoder import Encoder\n",
    "\n",
    "# Define a simple args class to hold the parameters\n",
    "class Args:\n",
    "    def __init__(self, image_channels, latent_dim):\n",
    "        self.image_channels = image_channels\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "# Initialize the arguments\n",
    "args = Args(image_channels=3, latent_dim=64)  # For example, using RGB images and a latent dimension of 64\n",
    "\n",
    "# Instantiate the Encoder\n",
    "encoder = Encoder(args)\n",
    "\n",
    "# Print the model architecture (optional)\n",
    "print(encoder)\n",
    "\n",
    "# Create a random input tensor with the shape (batch_size, image_channels, height, width)\n",
    "batch_size = 4\n",
    "image_height = 256\n",
    "image_width = 256\n",
    "input_tensor = torch.randn(batch_size, args.image_channels, image_height, image_width)\n",
    "\n",
    "# Forward pass through the encoder\n",
    "output = encoder(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (2): NonLocalBlock(\n",
      "      (gn): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "      (theta): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (phi): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (g): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (output_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (10): UpsampleBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (11): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (12): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (13): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (14): UpsampleBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (15): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (16): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (17): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (18): UpsampleBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (19): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (20): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (21): ResBlock(\n",
      "      (activation): SiLU()\n",
      "      (blocks): Sequential(\n",
      "        (0): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "        (4): SiLU()\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (residual): Identity()\n",
      "    )\n",
      "    (22): UpsampleBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (23): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
      "    (24): SiLU()\n",
      "    (25): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Output shape: torch.Size([4, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from decoder import Decoder\n",
    "\n",
    "\n",
    "# Define a simple args class to hold the parameters\n",
    "class Args:\n",
    "    def __init__(self, image_channels, latent_dim):\n",
    "        self.image_channels = image_channels\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "# Initialize the arguments\n",
    "args = Args(image_channels=3, latent_dim=64)  # For example, using RGB images and a latent dimension of 64\n",
    "\n",
    "# Instantiate the Decoder\n",
    "decoder = Decoder(args)\n",
    "\n",
    "# Print the model architecture (optional)\n",
    "print(decoder)\n",
    "\n",
    "# Create a random input tensor with the shape (batch_size, latent_dim, height, width)\n",
    "batch_size = 4\n",
    "latent_height = 16\n",
    "latent_width = 16\n",
    "input_tensor = torch.randn(batch_size, args.latent_dim, latent_height, latent_width)\n",
    "\n",
    "# Forward pass through the decoder\n",
    "output = decoder(input_tensor)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from vqema import VectorQuantizerEMA\n",
    "class Args:\n",
    "    def __init__(self, image_channels, latent_dim):\n",
    "        self.image_channels = image_channels\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "# Initialize the arguments\n",
    "args = Args(image_channels=3, latent_dim=64)\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, in_channels, num_embeddings, embedding_dim, commitment_cost, decay):\n",
    "        super(VQVAE, self).__init__()\n",
    "        self.encoder = Encoder(args=args)\n",
    "        self.vq = VectorQuantizerEMA(num_embeddings, embedding_dim, commitment_cost, decay)\n",
    "        self.decoder = Decoder(args=args)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_e = self.encoder(x)\n",
    "        vq_loss, z_q, _ = self.vq(z_e)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        loss = recon_loss + vq_loss\n",
    "        return loss, x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 128, 256, 256]           3,584\n",
      "          Identity-2        [-1, 128, 256, 256]               0\n",
      "         GroupNorm-3        [-1, 128, 256, 256]             256\n",
      "              SiLU-4        [-1, 128, 256, 256]               0\n",
      "              SiLU-5        [-1, 128, 256, 256]               0\n",
      "            Conv2d-6        [-1, 128, 256, 256]         147,584\n",
      "         GroupNorm-7        [-1, 128, 256, 256]             256\n",
      "              SiLU-8        [-1, 128, 256, 256]               0\n",
      "              SiLU-9        [-1, 128, 256, 256]               0\n",
      "           Conv2d-10        [-1, 128, 256, 256]         147,584\n",
      "         ResBlock-11        [-1, 128, 256, 256]               0\n",
      "         Identity-12        [-1, 128, 256, 256]               0\n",
      "        GroupNorm-13        [-1, 128, 256, 256]             256\n",
      "             SiLU-14        [-1, 128, 256, 256]               0\n",
      "             SiLU-15        [-1, 128, 256, 256]               0\n",
      "           Conv2d-16        [-1, 128, 256, 256]         147,584\n",
      "        GroupNorm-17        [-1, 128, 256, 256]             256\n",
      "             SiLU-18        [-1, 128, 256, 256]               0\n",
      "             SiLU-19        [-1, 128, 256, 256]               0\n",
      "           Conv2d-20        [-1, 128, 256, 256]         147,584\n",
      "         ResBlock-21        [-1, 128, 256, 256]               0\n",
      "           Conv2d-22        [-1, 128, 128, 128]         147,584\n",
      "  DownsampleBlock-23        [-1, 128, 128, 128]               0\n",
      "         Identity-24        [-1, 128, 128, 128]               0\n",
      "        GroupNorm-25        [-1, 128, 128, 128]             256\n",
      "             SiLU-26        [-1, 128, 128, 128]               0\n",
      "             SiLU-27        [-1, 128, 128, 128]               0\n",
      "           Conv2d-28        [-1, 128, 128, 128]         147,584\n",
      "        GroupNorm-29        [-1, 128, 128, 128]             256\n",
      "             SiLU-30        [-1, 128, 128, 128]               0\n",
      "             SiLU-31        [-1, 128, 128, 128]               0\n",
      "           Conv2d-32        [-1, 128, 128, 128]         147,584\n",
      "         ResBlock-33        [-1, 128, 128, 128]               0\n",
      "         Identity-34        [-1, 128, 128, 128]               0\n",
      "        GroupNorm-35        [-1, 128, 128, 128]             256\n",
      "             SiLU-36        [-1, 128, 128, 128]               0\n",
      "             SiLU-37        [-1, 128, 128, 128]               0\n",
      "           Conv2d-38        [-1, 128, 128, 128]         147,584\n",
      "        GroupNorm-39        [-1, 128, 128, 128]             256\n",
      "             SiLU-40        [-1, 128, 128, 128]               0\n",
      "             SiLU-41        [-1, 128, 128, 128]               0\n",
      "           Conv2d-42        [-1, 128, 128, 128]         147,584\n",
      "         ResBlock-43        [-1, 128, 128, 128]               0\n",
      "           Conv2d-44          [-1, 128, 64, 64]         147,584\n",
      "  DownsampleBlock-45          [-1, 128, 64, 64]               0\n",
      "           Conv2d-46          [-1, 256, 64, 64]          33,024\n",
      "        GroupNorm-47          [-1, 128, 64, 64]             256\n",
      "             SiLU-48          [-1, 128, 64, 64]               0\n",
      "             SiLU-49          [-1, 128, 64, 64]               0\n",
      "           Conv2d-50          [-1, 256, 64, 64]         295,168\n",
      "        GroupNorm-51          [-1, 256, 64, 64]             512\n",
      "             SiLU-52          [-1, 256, 64, 64]               0\n",
      "             SiLU-53          [-1, 256, 64, 64]               0\n",
      "           Conv2d-54          [-1, 256, 64, 64]         590,080\n",
      "         ResBlock-55          [-1, 256, 64, 64]               0\n",
      "         Identity-56          [-1, 256, 64, 64]               0\n",
      "        GroupNorm-57          [-1, 256, 64, 64]             512\n",
      "             SiLU-58          [-1, 256, 64, 64]               0\n",
      "             SiLU-59          [-1, 256, 64, 64]               0\n",
      "           Conv2d-60          [-1, 256, 64, 64]         590,080\n",
      "        GroupNorm-61          [-1, 256, 64, 64]             512\n",
      "             SiLU-62          [-1, 256, 64, 64]               0\n",
      "             SiLU-63          [-1, 256, 64, 64]               0\n",
      "           Conv2d-64          [-1, 256, 64, 64]         590,080\n",
      "         ResBlock-65          [-1, 256, 64, 64]               0\n",
      "           Conv2d-66          [-1, 256, 32, 32]         590,080\n",
      "  DownsampleBlock-67          [-1, 256, 32, 32]               0\n",
      "         Identity-68          [-1, 256, 32, 32]               0\n",
      "        GroupNorm-69          [-1, 256, 32, 32]             512\n",
      "             SiLU-70          [-1, 256, 32, 32]               0\n",
      "             SiLU-71          [-1, 256, 32, 32]               0\n",
      "           Conv2d-72          [-1, 256, 32, 32]         590,080\n",
      "        GroupNorm-73          [-1, 256, 32, 32]             512\n",
      "             SiLU-74          [-1, 256, 32, 32]               0\n",
      "             SiLU-75          [-1, 256, 32, 32]               0\n",
      "           Conv2d-76          [-1, 256, 32, 32]         590,080\n",
      "         ResBlock-77          [-1, 256, 32, 32]               0\n",
      "         Identity-78          [-1, 256, 32, 32]               0\n",
      "        GroupNorm-79          [-1, 256, 32, 32]             512\n",
      "             SiLU-80          [-1, 256, 32, 32]               0\n",
      "             SiLU-81          [-1, 256, 32, 32]               0\n",
      "           Conv2d-82          [-1, 256, 32, 32]         590,080\n",
      "        GroupNorm-83          [-1, 256, 32, 32]             512\n",
      "             SiLU-84          [-1, 256, 32, 32]               0\n",
      "             SiLU-85          [-1, 256, 32, 32]               0\n",
      "           Conv2d-86          [-1, 256, 32, 32]         590,080\n",
      "         ResBlock-87          [-1, 256, 32, 32]               0\n",
      "           Conv2d-88          [-1, 256, 16, 16]         590,080\n",
      "  DownsampleBlock-89          [-1, 256, 16, 16]               0\n",
      "           Conv2d-90          [-1, 512, 16, 16]         131,584\n",
      "        GroupNorm-91          [-1, 256, 16, 16]             512\n",
      "             SiLU-92          [-1, 256, 16, 16]               0\n",
      "             SiLU-93          [-1, 256, 16, 16]               0\n",
      "           Conv2d-94          [-1, 512, 16, 16]       1,180,160\n",
      "        GroupNorm-95          [-1, 512, 16, 16]           1,024\n",
      "             SiLU-96          [-1, 512, 16, 16]               0\n",
      "             SiLU-97          [-1, 512, 16, 16]               0\n",
      "           Conv2d-98          [-1, 512, 16, 16]       2,359,808\n",
      "         ResBlock-99          [-1, 512, 16, 16]               0\n",
      "        Identity-100          [-1, 512, 16, 16]               0\n",
      "       GroupNorm-101          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-102          [-1, 512, 16, 16]               0\n",
      "            SiLU-103          [-1, 512, 16, 16]               0\n",
      "          Conv2d-104          [-1, 512, 16, 16]       2,359,808\n",
      "       GroupNorm-105          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-106          [-1, 512, 16, 16]               0\n",
      "            SiLU-107          [-1, 512, 16, 16]               0\n",
      "          Conv2d-108          [-1, 512, 16, 16]       2,359,808\n",
      "        ResBlock-109          [-1, 512, 16, 16]               0\n",
      "        Identity-110          [-1, 512, 16, 16]               0\n",
      "       GroupNorm-111          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-112          [-1, 512, 16, 16]               0\n",
      "            SiLU-113          [-1, 512, 16, 16]               0\n",
      "          Conv2d-114          [-1, 512, 16, 16]       2,359,808\n",
      "       GroupNorm-115          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-116          [-1, 512, 16, 16]               0\n",
      "            SiLU-117          [-1, 512, 16, 16]               0\n",
      "          Conv2d-118          [-1, 512, 16, 16]       2,359,808\n",
      "        ResBlock-119          [-1, 512, 16, 16]               0\n",
      "          Conv2d-120          [-1, 512, 16, 16]         262,656\n",
      "          Conv2d-121          [-1, 512, 16, 16]         262,656\n",
      "          Conv2d-122          [-1, 512, 16, 16]         262,656\n",
      "          Conv2d-123          [-1, 512, 16, 16]         262,656\n",
      "          Conv2d-124          [-1, 512, 16, 16]         262,656\n",
      "   NonLocalBlock-125          [-1, 512, 16, 16]               0\n",
      "        Identity-126          [-1, 512, 16, 16]               0\n",
      "       GroupNorm-127          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-128          [-1, 512, 16, 16]               0\n",
      "            SiLU-129          [-1, 512, 16, 16]               0\n",
      "          Conv2d-130          [-1, 512, 16, 16]       2,359,808\n",
      "       GroupNorm-131          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-132          [-1, 512, 16, 16]               0\n",
      "            SiLU-133          [-1, 512, 16, 16]               0\n",
      "          Conv2d-134          [-1, 512, 16, 16]       2,359,808\n",
      "        ResBlock-135          [-1, 512, 16, 16]               0\n",
      "       GroupNorm-136          [-1, 512, 16, 16]           1,024\n",
      "            SiLU-137          [-1, 512, 16, 16]               0\n",
      "          Conv2d-138           [-1, 64, 16, 16]         294,976\n",
      "================================================================\n",
      "Total params: 26,571,584\n",
      "Trainable params: 26,571,584\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 1943.62\n",
      "Params size (MB): 101.36\n",
      "Estimated Total Size (MB): 2045.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "in_channels = 3\n",
    "num_embeddings = 512\n",
    "embedding_dim = 64\n",
    "commitment_cost = 0.25\n",
    "decay = 0.99\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Initialize models\n",
    "\n",
    "vqvae = VQVAE(in_channels, num_embeddings, embedding_dim, commitment_cost, decay).to(device)\n",
    "en = Encoder(args=args).to(device)\n",
    "\n",
    "summary(en, (3, 256, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params in Model: 62573379\n"
     ]
    }
   ],
   "source": [
    "print('Number of params in Model: {}'.format(\n",
    "    sum(p.data.nelement() for p in vqvae.parameters() if p.requires_grad),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training from Scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25325 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 1/25325 [00:16<114:59:43, 16.35s/it, Training loss=0.607, Batch loss=1.214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 2/25325 [00:28<95:58:56, 13.65s/it, Training loss=1.394, Batch loss=2.970] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 3/25325 [00:40<90:58:28, 12.93s/it, Training loss=1.580, Batch loss=2.137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 4/25325 [00:52<87:53:44, 12.50s/it, Training loss=2.088, Batch loss=4.121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 5/25325 [01:03<86:20:29, 12.28s/it, Training loss=2.067, Batch loss=1.962]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 6/25325 [01:15<85:50:33, 12.21s/it, Training loss=1.969, Batch loss=1.377]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 7/25325 [01:28<86:08:29, 12.25s/it, Training loss=2.004, Batch loss=2.254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 8/25325 [01:40<86:51:09, 12.35s/it, Training loss=1.934, Batch loss=1.374]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 9/25325 [01:52<85:39:21, 12.18s/it, Training loss=1.798, Batch loss=0.572]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 10/25325 [02:04<85:03:03, 12.09s/it, Training loss=1.699, Batch loss=0.705]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 11/25325 [02:16<84:24:17, 12.00s/it, Training loss=1.781, Batch loss=2.685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 12/25325 [02:28<83:56:01, 11.94s/it, Training loss=2.206, Batch loss=7.312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 13/25325 [02:40<83:42:54, 11.91s/it, Training loss=2.623, Batch loss=8.036]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 14/25325 [02:51<83:31:09, 11.88s/it, Training loss=2.902, Batch loss=6.820]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 15/25325 [03:04<84:11:29, 11.98s/it, Training loss=2.953, Batch loss=3.719]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 16/25325 [03:21<96:38:43, 13.75s/it, Training loss=2.916, Batch loss=2.319]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 17/25325 [03:38<101:51:35, 14.49s/it, Training loss=2.847, Batch loss=1.668]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 18/25325 [03:54<105:24:47, 15.00s/it, Training loss=2.769, Batch loss=1.370]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 19/25325 [04:11<110:26:52, 15.71s/it, Training loss=2.698, Batch loss=1.338]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 20/25325 [04:28<112:28:15, 16.00s/it, Training loss=2.619, Batch loss=1.052]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 21/25325 [04:44<112:45:48, 16.04s/it, Training loss=2.538, Batch loss=0.829]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 22/25325 [04:59<111:34:04, 15.87s/it, Training loss=2.472, Batch loss=1.019]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 23/25325 [05:16<112:52:41, 16.06s/it, Training loss=2.410, Batch loss=0.989]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 24/25325 [05:32<112:24:13, 15.99s/it, Training loss=2.353, Batch loss=0.994]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 25/25325 [05:49<115:44:27, 16.47s/it, Training loss=2.314, Batch loss=1.343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 26/25325 [06:05<114:43:49, 16.33s/it, Training loss=2.291, Batch loss=1.690]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 27/25325 [06:21<114:01:27, 16.23s/it, Training loss=2.267, Batch loss=1.612]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 28/25325 [06:38<115:51:00, 16.49s/it, Training loss=2.244, Batch loss=1.603]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 29/25325 [06:57<119:25:18, 17.00s/it, Training loss=2.217, Batch loss=1.436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 30/25325 [07:13<119:10:00, 16.96s/it, Training loss=2.184, Batch loss=1.192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 31/25325 [07:31<120:42:48, 17.18s/it, Training loss=2.147, Batch loss=0.986]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 32/25325 [07:48<120:18:10, 17.12s/it, Training loss=2.103, Batch loss=0.717]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 33/25325 [08:07<124:18:22, 17.69s/it, Training loss=2.057, Batch loss=0.525]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 34/25325 [08:29<132:39:57, 18.88s/it, Training loss=2.011, Batch loss=0.448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 35/25325 [08:46<129:25:36, 18.42s/it, Training loss=1.967, Batch loss=0.441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 36/25325 [09:02<124:44:09, 17.76s/it, Training loss=1.926, Batch loss=0.441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 37/25325 [09:20<123:22:16, 17.56s/it, Training loss=1.888, Batch loss=0.467]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 38/25325 [09:36<120:33:42, 17.16s/it, Training loss=1.854, Batch loss=0.586]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 39/25325 [09:53<120:07:26, 17.10s/it, Training loss=1.819, Batch loss=0.451]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 40/25325 [10:10<120:37:12, 17.17s/it, Training loss=1.784, Batch loss=0.375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 41/25325 [10:27<120:20:49, 17.14s/it, Training loss=1.750, Batch loss=0.368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 42/25325 [10:47<126:28:58, 18.01s/it, Training loss=1.717, Batch loss=0.317]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 43/25325 [11:05<125:08:00, 17.82s/it, Training loss=1.686, Batch loss=0.337]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 44/25325 [11:23<126:38:14, 18.03s/it, Training loss=1.657, Batch loss=0.400]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 45/25325 [11:44<131:59:11, 18.80s/it, Training loss=1.634, Batch loss=0.613]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 46/25325 [12:01<129:19:44, 18.42s/it, Training loss=1.618, Batch loss=0.845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 47/25325 [12:20<129:44:30, 18.48s/it, Training loss=1.609, Batch loss=1.216]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 48/25325 [12:40<133:52:47, 19.07s/it, Training loss=1.608, Batch loss=1.531]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "in_channels = 3\n",
    "num_embeddings = 512\n",
    "embedding_dim = 64\n",
    "commitment_cost = 0.25\n",
    "decay = 0.99\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "model_dir = \"checkpoints\"\n",
    "sample_dir = \"samples\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate model\n",
    "vqvae = VQVAE(in_channels, num_embeddings, embedding_dim, commitment_cost, decay).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(vqvae.parameters(), lr=learning_rate)\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "def find_latest_checkpoint(checkpoints_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoints_dir) if f.endswith('.pth')]\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "    return os.path.join(checkpoints_dir, latest_checkpoint)\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    vqvae.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    return start_epoch\n",
    "\n",
    "# Load the latest checkpoint if available\n",
    "start_epoch = 0\n",
    "latest_checkpoint = find_latest_checkpoint(model_dir)\n",
    "if latest_checkpoint:\n",
    "    start_epoch = load_checkpoint(latest_checkpoint)\n",
    "    print(f'Resuming training from epoch {start_epoch}')\n",
    "else:\n",
    "    print(f'Training from Scratch')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    train_loss = 0\n",
    "    with tqdm(enumerate(train_loader, start=1), total=len(train_loader)) as t:\n",
    "        for batch_idx, (data, _) in t:\n",
    "            print(batch_idx)\n",
    "            data = data.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss, _ = vqvae(data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            t.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            t.set_postfix({'Training loss': f'{train_loss/(batch_idx+1):.3f}', 'Batch loss': f'{loss:.3f}'})\n",
    "            \n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{epochs} Average Loss: {train_loss}')\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(model_dir, f'vqvae_epoch_{epoch+1}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': vqvae.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save some reconstructed images for visualization\n",
    "    vqvae.eval()\n",
    "    with torch.no_grad():\n",
    "        sample = next(iter(train_loader))[0].to(device)\n",
    "        _, recon_sample = vqvae(sample)\n",
    "        recon_sample = recon_sample.cpu()\n",
    "        save_image(recon_sample, os.path.join(sample_dir, f'epoch_{epoch+1}_reconstructions.png'))\n",
    "        save_image(sample.cpu(), os.path.join(sample_dir, f'epoch_{epoch+1}_originals.png'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
